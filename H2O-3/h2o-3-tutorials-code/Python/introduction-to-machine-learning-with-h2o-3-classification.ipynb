{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import H2O and other libaries that will be used in this tutorial \n",
    "import h2o\n",
    "from h2o.estimators import *\n",
    "from h2o.grid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "startup  = '/home/h2o/bin/aquarium_startup'\n",
    "shutdown = '/home/h2o/bin/aquarium_stop'\n",
    "\n",
    "if os.path.exists(startup):\n",
    "    os.system(startup)\n",
    "    local_url = 'http://localhost:54321/h2o'\n",
    "    aquarium = True\n",
    "else:\n",
    "    local_url = 'http://localhost:54321'\n",
    "    aquarium = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init(url = local_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset \n",
    "loan_level = h2o.import_file(\"https://s3.amazonaws.com/data.h2o.ai/DAI-Tutorials/loan_level_500k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Machine Learning Concepts - See Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Start Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_level.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_level[\"DELINQUENT\"].table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = loan_level.split_frame([0.7, 0.15], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:%d valid:%d test:%d\" % (train.nrows, valid.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"DELINQUENT\"\n",
    "\n",
    "ignore = [\"DELINQUENT\", \"PREPAID\", \"PREPAYMENT_PENALTY_MORTGAGE_FLAG\", \"PRODUCT_TYPE\"] \n",
    "\n",
    "x = list(set(train.names) - set(ignore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Build a GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = H2OGeneralizedLinearEstimator(family = \"binomial\", seed = 42, model_id = 'default_glm')\n",
    "%time glm.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.accuracy() #You can print individual metrics as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glm.predict(valid).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_glm_perf = glm.model_performance(valid) #validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(default_glm_perf.auc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Build a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = H2ORandomForestEstimator (seed = 42, model_id = 'default_rf')\n",
    "%time rf.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.plot(metric = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf.varimp_plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This is a bonus feature for this tutorial!\n",
    "rf.partial_plot(data = train, cols = ['CREDIT_SCORE'], \n",
    "                server = True, plot = True) #Partial Dependence plots can also be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.accuracy() #Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.F1() #Training F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_rf_per = rf.model_performance(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Build a GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = H2OGradientBoostingEstimator(seed = 42, model_id = 'default_gbm')\n",
    "%time gbm.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gbm_per = gbm.model_performance(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gbm_per.auc() #validation AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gbm_per.F1() #Validation F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Tune the GLM with H2O GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_grid = h2o.grid.H2OGridSearch (\n",
    "    \n",
    "    H2OGeneralizedLinearEstimator(family = \"binomial\",\n",
    "                                  lambda_search = True),\n",
    "    \n",
    "    hyper_params = {\"alpha\": [x*0.01 for x in range(0, 100)],\n",
    "                    \"missing_values_handling\" : [\"Skip\", \"MeanImputation\"]\n",
    "                    },\n",
    "    \n",
    "    grid_id = \"glm_random_grid\",\n",
    "    \n",
    "    search_criteria = {\n",
    "        \"strategy\":\"RandomDiscrete\",\n",
    "        \"max_models\":300,\n",
    "        \"max_runtime_secs\":300,\n",
    "        \"seed\":42\n",
    "        }\n",
    ")\n",
    "\n",
    "%time glm_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_glm_grid = glm_grid.get_grid(sort_by = 'auc', decreasing = True)\n",
    "sorted_glm_grid.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_glm = sorted_glm_grid.models[0]\n",
    "tuned_glm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_glm_perf = tuned_glm.model_performance(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Default GLM AUC: %.4f \\nTuned GLM AUC:%.4f\" % (default_glm_perf.auc(), tuned_glm_perf.auc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not shown in Tutorial\n",
    "print (\"Default GLM Accuracy:\", default_glm_perf.accuracy())\n",
    "print (\"Tuned GLM Accuracy\", tuned_glm_perf.accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Default GLM F1 Score:\", default_glm_perf.F1())\n",
    "print (\"Tuned GLM F1 Score\", tuned_glm_perf.F1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Default GLM: \", default_glm_perf.confusion_matrix())\n",
    "print (\"Tuned GLM: \",  tuned_glm_perf.confusion_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Tune the RF model with H2O GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search Parameters\n",
    "hyper_parameters = {'max_depth':[1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 15, 20, 25, 35]}\n",
    "\n",
    "rf = H2ORandomForestEstimator(seed = 42,\n",
    "                              stopping_rounds = 5, \n",
    "                              stopping_tolerance = 1e-4, \n",
    "                              stopping_metric = \"auc\",\n",
    "                              model_id = 'rf')\n",
    "\n",
    "grid_id = 'depth_grid'\n",
    "\n",
    "search_criteria = {'strategy': \"Cartesian\"}\n",
    "\n",
    "#Grid Search\n",
    "rf_grid = H2OGridSearch(model = rf, \n",
    "                        hyper_params = hyper_parameters, \n",
    "                        grid_id = grid_id, \n",
    "                        search_criteria = search_criteria)\n",
    "\n",
    "%time rf_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rf_depth = rf_grid.get_grid(sort_by = 'auc',decreasing = True)\n",
    "sorted_rf_depth.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\"max_depth\":[8, 9, 10, 11, 12],\n",
    "                    'sample_rate': [x/100. for x in range(20,101)]\n",
    "                   }\n",
    "\n",
    "rf = H2ORandomForestEstimator(ntrees = 500,\n",
    "                              seed = 42,\n",
    "                              stopping_rounds = 5, \n",
    "                              stopping_tolerance = 1e-3, \n",
    "                              stopping_metric = \"auc\",\n",
    "                              model_id = 'rf_grid')\n",
    "\n",
    "grid_id = 'rf_random_grid'\n",
    "\n",
    "search_criteria = {\"strategy\":\"RandomDiscrete\",\n",
    "                   \"max_models\":100,\n",
    "                   \"max_runtime_secs\":900,\n",
    "                   \"seed\":42\n",
    "                  }\n",
    "\n",
    "rf_grid = H2OGridSearch(model = rf, \n",
    "                        hyper_params = hyper_parameters, \n",
    "                        grid_id = grid_id, \n",
    "                        search_criteria = search_criteria)\n",
    "\n",
    "%time rf_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_rf = rf_grid.get_grid(sort_by = 'auc',decreasing = True)\n",
    "sorted_rf.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf = sorted_rf.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf_per = tuned_rf.model_performance(valid)\n",
    "tuned_rf_per.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_rf_per.F1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Default RF AUC: %.4f \\nTuned RF AUC:%.4f\" % (default_rf_per.auc(), tuned_rf_per.auc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Default RF F1 Score:\", default_rf_per.F1())\n",
    "print(\"Tuned RF F1 Score:\", tuned_rf_per.F1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Default RF: \", default_rf_per.confusion_matrix())\n",
    "print (\"Tuned RF: \",  tuned_rf_per.confusion_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Tune the GBM model with H2O GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'max_depth' : [3,4,5,6,7,8,9,10,12,13,15],\n",
    "               }\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(model_id = 'grid_gbm', \n",
    "                                   ntrees = 50,\n",
    "                                   seed = 42)\n",
    "\n",
    "gbm_grid = H2OGridSearch(gbm, hyper_params,\n",
    "                         grid_id = 'depth_gbm_grid',\n",
    "                         search_criteria = {\"strategy\":\"Cartesian\"})\n",
    "\n",
    "\n",
    "%time gbm_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_gbm_depth = gbm_grid.get_grid(sort_by = 'auc', decreasing = True)\n",
    "sorted_gbm_depth.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = H2OGradientBoostingEstimator(ntrees = 500,\n",
    "                                   learn_rate = 0.05,\n",
    "                                   seed = 42,\n",
    "                                   model_id = 'grid_gbm')\n",
    "\n",
    "hyper_params_tune = {'max_depth' : [4, 5, 6, 7, 8],\n",
    "                     'sample_rate': [x/100. for x in range(20,101)],\n",
    "                     'col_sample_rate' : [x/100. for x in range(20,101)],\n",
    "                     'col_sample_rate_per_tree': [x/100. for x in range(20,101)],\n",
    "                     'col_sample_rate_change_per_level': [x/100. for x in range(90,111)],\n",
    "                    }\n",
    "\n",
    "search_criteria_tune = {'strategy': \"RandomDiscrete\",\n",
    "                        'max_runtime_secs': 900,  \n",
    "                        'max_models': 100,  ## build no more than 100 models\n",
    "                        'seed' : 42 \n",
    "                       }\n",
    "\n",
    "random_grid = H2OGridSearch(model = gbm, hyper_params = hyper_params_tune,\n",
    "                            grid_id = 'random_grid',\n",
    "                            search_criteria = search_criteria_tune)\n",
    "\n",
    "%time random_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_random_search = random_grid.get_grid(sort_by = 'auc',decreasing = True)\n",
    "sorted_random_search.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbm = sorted_random_search.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbm_per = tuned_gbm.model_performance(valid)\n",
    "print(tuned_gbm_per.auc())\n",
    "print(tuned_gbm_per.F1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbm_per.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Default GBM AUC: %.4f \\nTuned GBM AUC:%.4f\" % (default_gbm_per.auc(), tuned_gbm_per.auc()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_test_per = tuned_glm.model_performance(test)\n",
    "rf_test_per = tuned_rf.model_performance(test)\n",
    "gbm_test_per = tuned_gbm.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"GLM Test AUC: %.4f \\nRF Test AUC: %.4f \\nGBM Test AUC: %.4f \" % \n",
    "      (glm_test_per.auc(), rf_test_per.auc(), gbm_test_per.auc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"GLM Test F1 Score: \", glm_test_per.F1())\n",
    "print (\"RF Test F1 Score: \",  rf_test_per.F1())\n",
    "print (\"GBM Test F1 Score: \",  gbm_test_per.F1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not shown in the tutorial file. Just for reference - using threshold that maximizes the F1\n",
    "print (\"GLM Test Accuracy: \", glm_test_per.accuracy(thresholds = 0.13108999388747938))\n",
    "print (\"RF Test Accuracy: \",  rf_test_per.accuracy(thresholds = 0.11901725589047217))\n",
    "print (\"GBM Test Accuracy: \",  gbm_test_per.accuracy(thresholds = 0.15601852885798811))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"GLM Confusion Matrix: \", glm_test_per.confusion_matrix())\n",
    "print (\"RF Confusion Matrix: \",  rf_test_per.confusion_matrix())\n",
    "print (\"GBM Confusion Matrix \",  gbm_test_per.confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not shown on tutorial file\n",
    "print(\"GLM Test logloss: %.5f \\nRF Test logloss: %.5f \\nGBM Test logloss: %.5f \" % \n",
    "      (glm_test_per.logloss(), rf_test_per.logloss(), gbm_test_per.logloss()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11: Challenge & Shutting down your Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2ONaiveBayesEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Build a bayes classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "bayes = H2ONaiveBayesEstimator(seed = 42)\n",
    "%time bayes.train(x, y, train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Check the validation AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "bayes_val_per = bayes.model_performance(valid)\n",
    "bayes_val_per.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Quick grid search for parameters laplace, min_prob and eps_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "hyper_params = {'laplace':[0, 0.1, 0.5, 1, 1.25, 1.75, 2, 2.25, 2.5, 3],\n",
    "                'min_prob':[0.0001, 0.001, 0.002, 0.005, 0.009, 0.01, 0.05, 0.1], \n",
    "                'eps_prob':[0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "               }\n",
    "\n",
    "bayes = H2ONaiveBayesEstimator(seed = 42)\n",
    "\n",
    "grid_id = 'bayes_grid'\n",
    "\n",
    "search_criteria = {\"strategy\" : 'RandomDiscrete',\n",
    "                    'max_models': 100\n",
    "                  }\n",
    "\n",
    "bayes_grid = H2OGridSearch(model = bayes,\n",
    "                           hyper_params = hyper_params,\n",
    "                           grid_id = grid_id,\n",
    "                           search_criteria = search_criteria\n",
    "                           )\n",
    "\n",
    "%time bayes_grid.train(x = x, y = y, training_frame = train, validation_frame = valid)\n",
    "\n",
    "sorted_grid = bayes_grid.get_grid(sort_by = 'auc', decreasing = True)\n",
    "sorted_grid.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Lastly, check the test AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "best_bayes_model = bayes_grid.models[0] \n",
    "bayes_test_per = best_bayes_model.model_performance(test)\n",
    "bayes_test_per.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
